{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orangutan Organoid Scanpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~15000 Cells from a 10x run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('agg') # plotting backend compatible with screen\n",
    "import scanpy\n",
    "import scanpy.api as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging as logg\n",
    "import os\n",
    "import loompy\n",
    "import scipy\n",
    "import re\n",
    "import anndata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.verbosity = 2\n",
    "sc.settings.autosave = True # save figures, do not show them\n",
    "sc.settings.set_figure_params(dpi=300) # set sufficiently high resolution for saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = os.path.expanduser('/ye/yelabstore2/mtschmitz/seq/AlignedOrangutanOrganoid/Exonic/orangutanorganoid_Out/outs')\n",
    "# Run louvain clustering on true gene expression values\n",
    "velocityFile = os.path.expanduser('/ye/yelabstore2/mtschmitz/seq/AlignedOrangutanOrganoid/Exonic/orangutanorganoid_Out/velocyto/orangutanorganoid_Out.loom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /home/mt/code/data/AlignedOrangutanOrganoid/Exonic/orangutanorganoid_Out/outs/filtered_gene_bc_matrices_h5.h5 Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "(0:00:00.33)\n"
     ]
    }
   ],
   "source": [
    "adata = sc.read_10x_h5('/home/mt/code/data/AlignedOrangutanOrganoid/Exonic/orangutanorganoid_Out/outs/filtered_gene_bc_matrices_h5.h5','refdata-celranger-Pabe2-toplevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def checkDuplicates(a):\n",
    "    return(len(a) == len(set(a)))\n",
    "    \n",
    "def gsub(regex, sub, l):\n",
    "    return([re.sub(regex, sub, x) for x in l])\n",
    "\n",
    "def orderIntersectLists(a,b):\n",
    "    set(a).intersection(b)\n",
    "\n",
    "def addCleanObsNames(adata,regex=\"-[0-9]\"):\n",
    "    try:\n",
    "        adata.obs.loc[:,\"clean_obs_names\"]=adata.obs.loc[:,\"clean_obs_names\"]\n",
    "    except:\n",
    "        adata.obs.loc[:,\"clean_obs_names\"]=adata.obs_names\n",
    "    adata.obs.loc[:,\"clean_obs_names\"]=gsub(regex, \"\",adata.obs.loc[:,\"clean_obs_names\"])\n",
    "    return(adata)\n",
    "    \n",
    "def removeVelocyto(adata):\n",
    "    adata.U=None\n",
    "    adata.S=None\n",
    "    return(adata)\n",
    "    \n",
    "def match(a,b):\n",
    "    return([ b.index(x) if x in b else None for x in a ])\n",
    "    \n",
    "    \n",
    "    \n",
    "def addVelocyto(adata,loomfile):\n",
    "    if not hasattr(adata, 'U'):\n",
    "        print('adding velocyto')\n",
    "        ds=loompy.connect(loomfile)\n",
    "        row_attrs = pd.DataFrame.from_dict(dict(ds.row_attrs.items()))\n",
    "        col_attrs = pd.DataFrame.from_dict(dict(ds.col_attrs.items()))\n",
    "\n",
    "        col_attrs.loc[:,\"clean_obs_names\"] = cell_names = gsub(\"^[a-zA-Z0-9_]+:\", \"\",col_attrs.loc[:,'CellID'])\n",
    "        col_attrs.loc[:,\"clean_obs_names\"] = cell_names = gsub(\"x\",\"\",col_attrs.loc[:,'clean_obs_names'])\n",
    "        \n",
    "        cell_names=list(adata.obs.loc[:,'clean_obs_names'])\n",
    "        cell_names = [cell for cell in list(col_attrs.loc[:,'clean_obs_names']) if cell in cell_names]\n",
    "        cell_index = match(list(col_attrs.loc[:,'clean_obs_names']),list(adata.obs.loc[:,'clean_obs_names']))\n",
    "        \n",
    "        gene_names = [gene for gene in row_attrs.loc[:,'Accession'] if gene in adata.var.loc[:,'gene_ids']]\n",
    "        gene_index = match(list(row_attrs.loc[:,'Accession']),list(adata.var.loc[:,'gene_ids']))\n",
    "        #print(adata.var)\n",
    "        #print(row_attrs)\n",
    "        #print(match(list(row_attrs.loc[:,'Accession']),list(adata.var.loc[:,'gene_ids'])))\n",
    "        #print(gene_index)\n",
    "        \n",
    "        #cols_to_use = col_attrs.columns.difference( adata.obs.columns)\n",
    "        adata.obs = pd.merge( adata.obs,col_attrs,how='outer',on=\"clean_obs_names\")\n",
    "        adata.obs.set_index('clean_obs_names')\n",
    "\n",
    "        #cols_to_use = row_attrs.columns.difference(adata.vars.columns)\n",
    "        adata.var=pd.merge( adata.var,row_attrs,how='outer',right_on=\"Accession\",left_on=\"gene_ids\")\n",
    "        adata.var.set_index('Gene')\n",
    "        \n",
    "        if len(cell_names) == 0:\n",
    "            raise ValueError(\n",
    "                'Cell names in loom file do not match cell names in AnnData.')\n",
    "        \n",
    "        from anndata.base import _normalize_index\n",
    "        norm_gene_index=_normalize_index(gene_index, pd.RangeIndex(len(gene_index)))\n",
    "        norm_cell_index=_normalize_index(cell_index, pd.RangeIndex(len(cell_index)))\n",
    "        \n",
    "        # subset to cells and genes present in adata. Do this with lists of integer indices\n",
    "        #adata.S = anndata.AnnData(ds.layer['spliced'].sparse().tocsr().T)\n",
    "        #adata.U = anndata.AnnData(ds.layer['unspliced'].sparse().tocsr().T)\n",
    "        adata.S = anndata.AnnData(ds.layer['spliced'].sparse(norm_gene_index,norm_cell_index).tocsr().T)\n",
    "        adata.U = anndata.AnnData(ds.layer['unspliced'].sparse(norm_gene_index,norm_cell_index).tocsr().T)\n",
    "        \n",
    "        ds.close()\n",
    "    return(adata,adataS,adataU)\n",
    "\n",
    "def openVelocyto(adata,loomfile):\n",
    "    print('adding velocyto')\n",
    "    ds=loompy.connect(loomfile)\n",
    "    row_attrs = pd.DataFrame.from_dict(dict(ds.row_attrs.items()))\n",
    "    col_attrs = pd.DataFrame.from_dict(dict(ds.col_attrs.items()))\n",
    "\n",
    "    col_attrs.loc[:,\"clean_obs_names\"] = cell_names = gsub(\"^[a-zA-Z0-9_]+:\", \"\",col_attrs.loc[:,'CellID'])\n",
    "    col_attrs.loc[:,\"clean_obs_names\"] = cell_names = gsub(\"x\",\"\",col_attrs.loc[:,'clean_obs_names'])\n",
    "\n",
    "    cell_names=list(adata.obs.loc[:,'clean_obs_names'])\n",
    "    cell_names = [cell for cell in list(col_attrs.loc[:,'clean_obs_names']) if cell in cell_names]\n",
    "    cell_index = match(list(col_attrs.loc[:,'clean_obs_names']),list(adata.obs.loc[:,'clean_obs_names']))\n",
    "\n",
    "    gene_names = [gene for gene in row_attrs.loc[:,'Accession'] if gene in adata.var.loc[:,'gene_ids']]\n",
    "    gene_index = match(list(row_attrs.loc[:,'Accession']),list(adata.var.loc[:,'gene_ids']))\n",
    "\n",
    "    #cols_to_use = col_attrs.columns.difference( adata.obs.columns)\n",
    "    adata.obs = pd.merge( adata.obs,col_attrs,how='left',on=\"clean_obs_names\")\n",
    "    adata.obs.set_index('clean_obs_names',drop=False)\n",
    "\n",
    "    #cols_to_use = row_attrs.columns.difference(adata.vars.columns)\n",
    "    vardata=pd.merge( adata.var,row_attrs,how='inner',right_on=\"Accession\",left_on=\"gene_ids\")\n",
    "    adata.var=vardata\n",
    "    adata.var.set_index('Gene',drop=False)\n",
    "\n",
    "    if len(cell_names) == 0:\n",
    "        raise ValueError(\n",
    "            'Cell names in loom file do not match cell names in AnnData.')\n",
    "\n",
    "    from anndata.base import _normalize_index\n",
    "    gene_index=[x for x in gene_index if x is not None]\n",
    "    cell_index=[x for x in cell_index if x is not None]\n",
    "    norm_gene_index=_normalize_index(gene_index, pd.RangeIndex(len(gene_index)))\n",
    "    norm_cell_index=_normalize_index(cell_index, pd.RangeIndex(len(cell_index)))\n",
    "\n",
    "    #adata.S = anndata.AnnData(ds.layer['spliced'].sparse().tocsr().T)\n",
    "    #adata.U = anndata.AnnData(ds.layer['unspliced'].sparse().tocsr().T)\n",
    "    # subset to cells and genes present in adata. Do this with lists of integer indices\n",
    "    adataS = anndata.AnnData(ds.layer['spliced'].sparse(norm_gene_index,norm_cell_index).tocsr().T)\n",
    "    adataU = anndata.AnnData(ds.layer['unspliced'].sparse(norm_gene_index,norm_cell_index).tocsr().T)\n",
    "    adataS.obs=pd.merge( adata.obs,col_attrs,how='inner',on=\"clean_obs_names\")\n",
    "    adataU.obs=pd.merge( adata.obs,col_attrs,how='inner',on=\"clean_obs_names\")\n",
    "    adataS.obs.set_index('clean_obs_names', drop=False)\n",
    "    adataU.obs.set_index('clean_obs_names', drop=False)\n",
    "    print(vardata.shape)\n",
    "    print(adataS.shape)\n",
    "    adataS.var=vardata\n",
    "    adataU.var=vardata\n",
    "    adataS.var.set_index('Gene', drop=False)\n",
    "    adataU.var.set_index('Gene', drop=False)\n",
    "    adataU.var_names=adataU.var.loc[:,\"Gene\"]\n",
    "    adataS.var_names=adataS.var.loc[:,\"Gene\"]\n",
    "\n",
    "    ds.close()\n",
    "    return(adata,adataS,adataU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loomfile= os.path.expanduser('~/code/data/AlignedOrangutanOrganoid/Exonic/orangutanorganoid_Out/velocyto/orangutanorganoid_Out.loom')\n",
    "ds=loompy.connect(loomfile)\n",
    "row_attrs = pd.DataFrame.from_dict(dict(ds.row_attrs.items()))\n",
    "col_attrs = pd.DataFrame.from_dict(dict(ds.col_attrs.items()))\n",
    "\n",
    "col_attrs.loc[:,\"clean_obs_names\"] = cell_names = gsub(\"^[a-zA-Z0-9_]+:\", \"\",col_attrs.loc[:,'CellID'])\n",
    "col_attrs.loc[:,\"clean_obs_names\"] = cell_names = gsub(\"x\",\"\",col_attrs.loc[:,'clean_obs_names'])\n",
    "cell_names=list(adata.obs.loc[:,'clean_obs_names'])\n",
    "cell_names = [cell for cell in list(col_attrs.loc[:,'clean_obs_names']) if cell in cell_names]\n",
    "cell_index = match(list(col_attrs.loc[:,'clean_obs_names']),list(adata.obs.loc[:,'clean_obs_names']))\n",
    "gene_names = [gene for gene in row_attrs.loc[:,'Accession'] if gene in adata.var.loc[:,'gene_ids']]\n",
    "gene_index = match(list(row_attrs.loc[:,'Accession']),list(adata.var.loc[:,'gene_ids']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding velocyto\n",
      "(26224, 7)\n",
      "(14742, 26224)\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    }
   ],
   "source": [
    "adata=addCleanObsNames(adata)\n",
    "adata,adataS,adataU=openVelocyto(adata, os.path.expanduser('~/code/data/AlignedOrangutanOrganoid/Exonic/orangutanorganoid_Out/velocyto/orangutanorganoid_Out.loom'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata.S = anndata.AnnData(ds.layer['spliced'].sparse(pd.Series(gene_index),pd.Series(cell_index)).tocsr().T)\n",
    "#adata.S = anndata.AnnData(ds.layer['spliced'].sparse(pd.Index(gene_index),pd.Index(cell_index)).tocsr().T)\n",
    "#adata.S = anndata.AnnData(ds.layer['spliced'].sparse(tuple(gene_index),tuple(cell_index)).tocsr().T)\n",
    "#print(anndata.base._normalize_index(cell_index, pd.RangeIndex(len(cell_index))))\n",
    "#adata.S = anndata.AnnData(ds.layer['spliced'].sparse(pd.RangeIndex(len(gene_index)),pd.RangeIndex(len(cell_index))).tocsr().T)\n",
    "from anndata.base import _normalize_index\n",
    "norm_gene_index=_normalize_index(gene_index, pd.RangeIndex(len(gene_index)))\n",
    "norm_cell_index=_normalize_index(cell_index, pd.RangeIndex(len(cell_index)))\n",
    "print(norm_gene_index[0:10])\n",
    "print(gene_index[0:10])\n",
    "print(row_attrs.loc[0:10,'Accession'])\n",
    "print(adata.var.loc[0:10,'gene_ids'])\n",
    "#adata.S = anndata.AnnData(ds.layer['spliced'].sparse(norm_gene_index,norm_cell_index).tocsr().T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 14742 × 26224 \n",
      "    obs: 'clean_obs_names', 'CellID_x', 'Clusters_x', '_X_x', '_Y_x', 'CellID_y', 'Clusters_y', '_X_y', '_Y_y'\n",
      "    var: 'gene_ids', 'Accession', 'Chromosome', 'End', 'Gene', 'Start', 'Strand'\n"
     ]
    }
   ],
   "source": [
    "print(adataS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_to_use = col_attrs.columns.difference( adata.obs.columns)\n",
    "adata.obs = pd.merge( adata.obs,col_attrs,how='outer',on=\"clean_obs_names\")\n",
    "adata.obs.set_index('clean_obs_names')\n",
    "\n",
    "#cols_to_use = row_attrs.columns.difference(adata.vars.columns)\n",
    "adata.var=pd.merge( adata.var,row_attrs,how='outer',right_on=\"Accession\",left_on=\"gene_ids\")\n",
    "adata.var.set_index('Gene')\n",
    "\n",
    "adata.S = anndata.AnnData(ds.layer['spliced'].sparse().tocsr().T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#adata=addCleanObsNames(adata)\n",
    "#adata=addVelocyto(adata, os.path.expanduser('~/code/data/AlignedOrangutanOrganoid/Exonic/orangutanorganoid_Out/velocyto/orangutanorganoid_Out.loom'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterSplicedAndUnspliced(adata,min_cells):\n",
    "    print(\"todo\")\n",
    "    \n",
    "def runVelocity(adata,ad_s,ad_u):\n",
    "    subset, _ = sc.pp.filter_genes(ad_u.X, min_cells=50)\n",
    "    print(np.sum(subset))\n",
    "    ad_s = ad_s[:, subset]\n",
    "    ad_u = ad_u[:, subset]\n",
    "    #ad_s.var_names = np.array(ad_u.var.loc[:,\"Gene\"])[subset]\n",
    "\n",
    "    # loop over genes\n",
    "    from scipy.sparse import dok_matrix\n",
    "    offset = np.zeros(ad_s.shape[1], dtype='float32')\n",
    "    gamma = np.zeros(ad_s.shape[1], dtype='float32')\n",
    "    X_du = dok_matrix(ad_s.shape, dtype='float32')\n",
    "    for i in range(ad_s.shape[1]):\n",
    "        x = ad_s.X[:, i].toarray()\n",
    "        y = ad_u.X[:, i].toarray()\n",
    "        subset = np.logical_and(x > 0, y > 0)\n",
    "        x = x[subset]\n",
    "        y = y[subset]\n",
    "        X = np.c_[np.ones(len(x)), x]\n",
    "        offset[i], gamma[i] = np.linalg.pinv(X).dot(y)\n",
    "        subset_indices = np.flatnonzero(subset)\n",
    "        index = subset_indices, np.array([i for dummy in subset_indices])\n",
    "        X_du[index] = y - gamma[i]*x - offset[i]\n",
    "        #plt.scatter(x, y)\n",
    "        #plt.scatter(x, gamma[i]*x + offset[i])\n",
    "        #plt.scatter(x, X_du[index].toarray()[0])\n",
    "        #plt.show()\n",
    "    X_du = X_du.tocoo().tocsr()\n",
    "\n",
    "    #Need to run this outside\n",
    "    #sc.pp.neighbors(adata[:,subset], n_neighbors=100)\n",
    "    #Also moved this outside\n",
    "    #graph = compute_velocity_graph(adata, ad_u, X_du)\n",
    "    return(adata,ad_u,X_du)\n",
    "\n",
    "def compute_velocity_graph(adata, adata_u, X_du):\n",
    "    if (adata.shape[0] != adata_u.shape[0]\n",
    "        or adata_u.shape[0] != X_du.shape[0]\n",
    "        or X_du.shape[0] != adata.shape[0]):\n",
    "        raise ValueError('Number of cells do not match.')\n",
    "\n",
    "    from scanpy.neighbors import Neighbors, get_indices_distances_from_sparse_matrix\n",
    "    neigh = Neighbors(adata)\n",
    "    knn_indices, knn_distances = get_indices_distances_from_sparse_matrix(\n",
    "        neigh.distances, neigh.n_neighbors)\n",
    "    n_obs = adata.n_obs\n",
    "    n_neighbors = neigh.n_neighbors\n",
    "\n",
    "    from numpy.linalg import norm\n",
    "    X_u = adata_u.X.toarray()\n",
    "    X_du = X_du.astype('float32').toarray()\n",
    "\n",
    "    def fill_graph():\n",
    "        rows = np.zeros((n_obs * n_neighbors), dtype=np.int64)\n",
    "        cols = np.zeros((n_obs * n_neighbors), dtype=np.int64)\n",
    "        vals = np.zeros((n_obs * n_neighbors), dtype=np.float32)\n",
    "        for i in range(n_obs):\n",
    "            if i % 100 == 0:\n",
    "                try:\n",
    "                    logg.info('{}/{},'.format(i, n_obs))\n",
    "                    print(i,n_obs)\n",
    "                except:\n",
    "                    print(i,n_obs)\n",
    "            for nj in range(n_neighbors):\n",
    "                j = knn_indices[i, nj]\n",
    "                if j != i:\n",
    "                    du_i = X_du[i]\n",
    "                    du_ji = X_u[j] - X_u[i]\n",
    "                    subset = np.logical_or(du_ji != 0, du_i != 0)\n",
    "                    du_i = du_i[subset]\n",
    "                    du_ji = du_ji[subset]\n",
    "                    # dividing this by norm(du_i) doesn't make much of a difference\n",
    "                    val = np.dot(du_ji, du_i) / norm(du_ji) / norm(du_i)\n",
    "                    # if val > 0, this means transitioning from i to j,\n",
    "                    # convention of standard stochastic matrices even though\n",
    "                    # this isn't one\n",
    "                    # the problem with velocities at the boundaries of the knn\n",
    "                    # graph is that, no matter in which direction they point,\n",
    "                    # they anticorrelate with all neighbors: hence, one will\n",
    "                    # always observe \"out-going\" velocity even if there is no\n",
    "                    # indication for that\n",
    "                    if True:  # val > 0:\n",
    "                        rows[i * n_neighbors + nj] = j\n",
    "                        cols[i * n_neighbors + nj] = i\n",
    "                        vals[i * n_neighbors + nj] = val\n",
    "        return rows, cols, vals\n",
    "\n",
    "    rows, cols, vals = fill_graph()\n",
    "    from scipy.sparse import coo_matrix\n",
    "    graph = coo_matrix((vals, (rows, cols)), shape=(n_obs, n_obs))\n",
    "    graph.eliminate_zeros()\n",
    "    \n",
    "    return(graph.tocsr())\n",
    "\n",
    "\n",
    "def compute_arrows_embedding(adata,basis=\"tsne\"):\n",
    "    if 'graph' not in adata.uns:\n",
    "        raise ValueError('`arrows=True` requires `tl.rna_velocity` to be run before.')\n",
    "    adjacency = adata.uns['graph']\n",
    "    # loop over columns of adjacency, this is where transitions start from\n",
    "    from numpy.linalg import norm\n",
    "    V = np.zeros((adjacency.shape[0],  adata.obsm['X_' + basis].shape[1]), dtype='float32')\n",
    "    for i, n in enumerate(adjacency.T):  # loop over columns (note the transposition)\n",
    "        for j in n.nonzero()[1]:  # these are row indices\n",
    "            diff = adata.obsm['X_' + basis][j] - adata.obsm['X_' + basis][i]\n",
    "            # need the normalized difference vector: the distance in the embedding\n",
    "            # might be completely meaningless\n",
    "            diff /= norm(diff)\n",
    "            V[i] += adjacency[j, i] * diff\n",
    "    logg.info('added \\'V_{}\\' to `.obsm`'.format(basis))\n",
    "    adata.obsm['V_' + basis] = V\n",
    "    X = adata.obsm['X_' + basis]\n",
    "    for ax in axs:\n",
    "        quiver_kwds = arrows_kwds if arrows_kwds is not None else {}\n",
    "        ax.quiver(X[:, 0], X[:, 1], V[:, 0], V[:, 1], **quiver_kwds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[1,3,2,5]\n",
    "y=[0,0,10,0]\n",
    "X=np.c_[[1,1,1,1],x]\n",
    "print(X)\n",
    "print(np.linalg.pinv(X))\n",
    "print(np.linalg.pinv(X).dot(y))\n",
    "adata.obsm['X_pca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset, _ = sc.pp.filter_genes(adata.U.X, min_cells=50)\n",
    "#print(np.sum(adata.X,axis=0))\n",
    "#print(np.sum(adata.U.X,axis=0))\n",
    "#print(np.sum(adata.S.X,axis=0))\n",
    "#print([np.sum(adata.U.X,axis=0).tolist()[0],np.sum(adata.S.X,axis=0).tolist()[0]])\n",
    "#plt.scatter(np.sum(adata.U.X,axis=0).tolist()[0],np.sum(adata.S.X,axis=0).tolist()[0])\n",
    "#plt.scatter(adata.U.X.toarray()[1:100,1:1000],adata.S.X.toarray()[1:100,1:1000])\n",
    "#plt.scatter(adata.X.toarray()[1:100,1:1000],adata.S.X.toarray()[1:100,1:1000])\n",
    "#plt.show()\n",
    "cors=[]\n",
    "x=adata.X.toarray()\n",
    "y=adataU.X.toarray()\n",
    "for n in range(1000):\n",
    "    #n = np.random.randint(10000)\n",
    "    if np.sum(x[:,n])>0 and np.sum(y[:,n])>0:\n",
    "        cors.append(scipy.stats.pearsonr(x[:,n], y[:,n]))\n",
    "print(np.sum(x,axis=1)[1:100])\n",
    "print(np.sum(y,axis=1)[1:100])\n",
    "\n",
    "plt.hist([x[0] for x in cors])\n",
    "plt.scatter(adata.X.toarray()[1:1000,1:100],adataS.X.toarray()[1:1000,1:100])\n",
    "plt.show()\n",
    "\n",
    "print(adataS.var.loc[1:10,:])\n",
    "print(adata.var.loc[1:10,:])\n",
    "print(adata.var_names)\n",
    "adataU.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.pp.pca(adata)\n",
    "#sc.pp.neighbors(adata,knn=100)\n",
    "adata,ad_u,ad_X= runVelocity(adata,adataS,adataU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_u=ad_u\n",
    "X_du=ad_X\n",
    "if (adata.shape[0] != adata_u.shape[0]\n",
    "    or adata_u.shape[0] != X_du.shape[0]\n",
    "    or X_du.shape[0] != adata.shape[0]):\n",
    "    raise ValueError('Number of cells do not match.')\n",
    "\n",
    "from scanpy.neighbors import Neighbors, get_indices_distances_from_sparse_matrix\n",
    "neigh = Neighbors(adata)\n",
    "knn_indices, knn_distances = get_indices_distances_from_sparse_matrix(\n",
    "    neigh.distances, neigh.n_neighbors)\n",
    "n_obs = adata.n_obs\n",
    "n_neighbors = neigh.n_neighbors\n",
    "\n",
    "from numpy.linalg import norm\n",
    "X_u = adata_u.X.toarray()\n",
    "X_du = X_du.astype('float32').toarray()\n",
    "\n",
    "def fill_graph():\n",
    "    rows = np.zeros((n_obs * n_neighbors), dtype=np.int64)\n",
    "    cols = np.zeros((n_obs * n_neighbors), dtype=np.int64)\n",
    "    vals = np.zeros((n_obs * n_neighbors), dtype=np.float32)\n",
    "    for i in range(n_obs):\n",
    "        if i % 100 == 0:\n",
    "            try:\n",
    "                logg.info('{}/{},'.format(i, n_obs))\n",
    "                print(i,n_obs)\n",
    "            except:\n",
    "                print(i,n_obs)\n",
    "        for nj in range(n_neighbors):\n",
    "            j = knn_indices[i, nj]\n",
    "            if j != i:\n",
    "                du_i = X_du[i]\n",
    "                du_ji = X_u[j] - X_u[i]\n",
    "                subset = np.logical_or(du_ji != 0, du_i != 0)\n",
    "                du_i = du_i[subset]\n",
    "                du_ji = du_ji[subset]\n",
    "                # dividing this by norm(du_i) doesn't make much of a difference\n",
    "                val = np.dot(du_ji, du_i) / norm(du_ji) / norm(du_i)\n",
    "                # if val > 0, this means transitioning from i to j,\n",
    "                # convention of standard stochastic matrices even though\n",
    "                # this isn't one\n",
    "                # the problem with velocities at the boundaries of the knn\n",
    "                # graph is that, no matter in which direction they point,\n",
    "                # they anticorrelate with all neighbors: hence, one will\n",
    "                # always observe \"out-going\" velocity even if there is no\n",
    "                # indication for that\n",
    "                if True:  # val > 0:\n",
    "                    rows[i * n_neighbors + nj] = j\n",
    "                    cols[i * n_neighbors + nj] = i\n",
    "                    vals[i * n_neighbors + nj] = val\n",
    "    return rows, cols, vals\n",
    "\n",
    "rows, cols, vals = fill_graph()\n",
    "from scipy.sparse import coo_matrix\n",
    "graph = coo_matrix((vals, (rows, cols)), shape=(n_obs, n_obs))\n",
    "graph.eliminate_zeros()\n",
    "graph.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['graph']=compute_velocity_graph(adata,ad_u,ad_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adata.uns['graph'])\n",
    "compute_arrows_embedding(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.tl.tsne(adata)\n",
    "basis=\"pca\"\n",
    "if 'graph' not in adata.uns:\n",
    "    raise ValueError('`arrows=True` requires `tl.rna_velocity` to be run before.')\n",
    "adjacency = adata.uns['graph']\n",
    "# loop over columns of adjacency, this is where transitions start from\n",
    "from numpy.linalg import norm\n",
    "V = np.zeros((adjacency.shape[0],  adata.obsm['X_' + basis].shape[1]), dtype='float32')\n",
    "for i, n in enumerate(adjacency.T):  # loop over columns (note the transposition)\n",
    "    for j in n.nonzero()[1]:  # these are row indices\n",
    "        diff = adata.obsm['X_' + basis][j] - adata.obsm['X_' + basis][i]\n",
    "        # need the normalized difference vector: the distance in the embedding\n",
    "        # might be completely meaningless\n",
    "        diff /= norm(diff)\n",
    "        V[i] += adjacency[j, i] * diff\n",
    "logg.info('added \\'V_{}\\' to `.obsm`'.format(basis))\n",
    "adata.obsm['V_' + basis] = V\n",
    "X = adata.obsm['X_' + basis]\n",
    "#for ax in axs:\n",
    "#    quiver_kwds = arrows_kwds if arrows_kwds is not None else {}\n",
    "#    ax.quiver(X[:, 0], X[:, 1], V[:, 0], V[:, 1], **quiver_kwds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adata.obsm['V_tsne'])\n",
    "print(adata.obs)\n",
    "sc.pl.scatter(adata,x='_X',y='_Y',color='Clusters')\n",
    "sc.tl.draw_graph(adata)\n",
    "sc.pl.draw_graph(adata,arrows=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
